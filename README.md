# Blueâ€“Green Deployment on AWS using kOps (Kubernetes)

A production-style **Blueâ€“Green deployment** implementation on **AWS** using **kOps-managed Kubernetes**. This project demonstrates zero-downtime releases, instant rollback, and real-world debugging of AWS LoadBalancer, Service selectors, ports, and ELB behavior.

---

## ğŸš€ Project Highlights

* Kubernetes cluster provisioned with **kOps** on AWS
* **Blueâ€“Green deployment** using two Deployments and one Service
* Public exposure via **Service type: LoadBalancer (AWS ELB)**
* Instant traffic switch & rollback using **Service selectors**
* Real-world debugging: ports, selectors, ELB health, DNS, NodePort

---

## ğŸ§± Architecture

```
Client
  â†“
AWS ELB (Service: LoadBalancer)
  â†“
NodePort (auto-managed)
  â†“
Pods (Blue or Green)
```

**Key idea:** The **Service selector controls traffic**, not the Deployment.

---

## ğŸ›  Tech Stack

* **Cloud:** AWS (EC2, ELB, S3)
* **Kubernetes:** kOps
* **Container Runtime:** containerd
* **Apps:**

  * Blue: nginx (port 80)
  * Green: Tomcat-based app (port 8080)

---

## ğŸ“¦ Cluster Setup (kOps)

* **Region:** ap-south-1
* **Cluster Name:** `kops.k8s.local`
* **State Store:** S3 (versioning enabled)
* **Topology:** Public
* **Nodes:** t2.micro
* **Master:** t2.medium

> kOps stores all cluster state in S3. Correct region configuration is mandatory.

---

## ğŸŸ¦ Blue Deployment (Stable)

* **Labels:** `app=web, env=blue`
* **Image:** `nginx`
* **Container Port:** `80`
* **Purpose:** Current stable version

---

## ğŸŸ© Green Deployment (New Version)

* **Labels:** `app=web, env=green`
* **Image:** Custom Tomcat app
* **Container Port:** `8080`
* **Purpose:** New release candidate

---

## ğŸŒ Service (Traffic Control)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: lb1
spec:
  type: LoadBalancer
  selector:
    app: web
    env: blue   # switch to green to route traffic
  ports:
    - port: 80
      targetPort: 80
```

### Traffic Switch

* `env=blue` â†’ nginx (Blue)
* `env=green` â†’ Tomcat (Green)

âœ” No downtime
âœ” No pod restart
âœ” Instant rollback

---

## ğŸ” Rollback Strategy

**Blueâ€“Green rollback** is done by switching the Service selector back:

```yaml
selector:
  app: web
  env: blue
```

This is faster and safer than `kubectl rollout undo`.

---

## ğŸ§ª Verification Commands

```bash
kubectl get deploy
kubectl get pods --show-labels
kubectl get svc lb1
kubectl get endpoints lb1
```

> **Endpoints** are the source of truth for where traffic is going.

---

## ğŸ Real Issues Debugged

* âŒ Immutable Deployment selectors
* âŒ Pod naming inside Deployments
* âŒ Port mismatch (80 vs 8080)
* âŒ NodePort blocked by AWS SG
* âŒ ELB with no healthy backends
* âŒ DNS typo (`.amazon` vs `.amazonaws.com`)

Each issue was fixed following production-grade debugging steps.

---

## ğŸ§  Key Learnings

* Service selectors control traffic
* `targetPort` must match the appâ€™s listening port
* NodePort is internal plumbing on AWS
* Use ELB DNS for public access
* Endpoints reveal the real routing state

---

## ğŸ§¹ Cleanup

```bash
AWS_DEFAULT_REGION=ap-south-1 \
kops delete cluster --name kops.k8s.local --state s3://kops-cluster-k8s --yes
```

---

## ğŸ“ˆ Future Improvements

* Add readiness & liveness probes
* Use Ingress + ALB
* CI/CD automation (GitHub Actions)
* Canary deployments

---

## ğŸ“Œ Author

**Sonu Kumar**
DevOps / Cloud Engineer

---

â­ If this helped you understand real Kubernetes deployments, give it a star!
